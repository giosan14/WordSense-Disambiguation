{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Universidad Internacional de La Rioja (UNIR) - Máster Universitario en Inteligencia Artificial - Procesamiento del Lenguaje Natural** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Datos del alumno:\n",
    "Santiago Guerrero Elias Giovanni\n",
    "\n",
    "Fecha:\n",
    "\n",
    "04/09/2022\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20pt; font-weight: bold; color: #0098cd;\">Actividad 3: Desambiguación del sentido de las palabras</span>\n",
    "\n",
    "**Objetivos** \n",
    "\n",
    "Con este laboratorio el alumno conseguirá aplicar diferentes algoritmos basados en aprendizaje automático supervisado para desambiguar el sentido de las palabras. Además, va a aprender a utilizar la herramienta de software abierto Natural Language Toolkit (NLTK) con la que implementar tareas de procesamiento del lenguaje natural en Python.\n",
    "\n",
    "**Descripción**\n",
    "\n",
    "En este laboratorio debes desarrollar e implementar diferentes algoritmos basados en aprendizaje automático supervisado para desambiguar el sentido de las palabras en Python y utilizando la herramienta de software abierto Natural Language Toolkit (NLTK).\n",
    "\n",
    "Para preparar este laboratorio, simplemente descarga e instala **NLTK 3.3** en tu equipo.\n",
    "\n",
    "***\n",
    "Accede a NLTK 3.3 desde la siguiente dirección web:\n",
    "https://www.nltk.org/install.html\n",
    "***\n",
    "\n",
    "NLTK requiere de Python versiones 2.7, 3.4, 3.5 o 3.6 para funcionar. Por lo que, si no tienes instalado Python, descárgalo e instálalo.\n",
    "\n",
    "***\n",
    "Accede a **Python**  desde la siguiente dirección web: https://www.python.org/downloads/\n",
    "***\n",
    "\n",
    "Asegúrate de que has instalado NLTK 3.3 adecuadamente antes de la sesión de laboratorio y de revisar el contenido teórico, Semántica léxica y temas anteriores, para tener frescos los diferentes conceptos sobre el procesamiento del lenguaje natural estudiados en esta asignatura.\n",
    "\n",
    "Durante la sesión del laboratorio debes solucionar un problema sobre desambiguación del sentido de las palabras utilizando el corpus etiquetado en inglés llamado **Senseval 2** y que viene disponible en NLTK.\n",
    "\n",
    "***\n",
    "Accede a más información sobre **Senseval 2** desde la siguiente dirección web:\n",
    "http://www.nltk.org/howto/corpus.html \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\giovanni\\anaconda3\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\giovanni\\anaconda3\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\giovanni\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\giovanni\\anaconda3\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\giovanni\\anaconda3\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\giovanni\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer paso es importar el corpus etiquetado utilizando los siguientes comandos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import senseval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El corpus **Senseval 2** contiene datos etiquetados que sirven para entrenar un clasificador que permita desambiguar el sentido de las palabras. Cada elemento del corpus **Senseval 2** se corresponde a una palabra ambigua. Concretamente en este laboratorio se trabajará con las palabras en inglés *«hard»* y *«serve»*, aunque en el corpus hay información de otras dos.\n",
    "\n",
    "Para poder extraer la información sobre las palabras es imprescindible la manera en la que se identifican en el corpus, es decir, sus identificadores. Con el siguiente comando, se extraen los identificadores de las palabras tratadas en el corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package senseval to\n",
      "[nltk_data]     C:\\Users\\Giovanni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package senseval is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('senseval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hard.pos', 'interest.pos', 'line.pos', 'serve.pos']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senseval.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada una de las palabras ambiguas, el corpus contiene una lista de instancias correspondientes a las ocurrencias de esa palabra. Para cada instancia se proporciona la palabra, una lista de sentidos que se aplican a la aparición de esa palabra y el contexto de la palabra. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente figura se observa el comando utilizado para visualizar la información que contiene cada instancia de la palabra ambigua *«hard»*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SensevalInstance(word='hard-a', position=20, context=[('``', '``'), ('he', 'PRP'), ('may', 'MD'), ('lose', 'VB'), ('all', 'DT'), ('popular', 'JJ'), ('support', 'NN'), (',', ','), ('but', 'CC'), ('someone', 'NN'), ('has', 'VBZ'), ('to', 'TO'), ('kill', 'VB'), ('him', 'PRP'), ('to', 'TO'), ('defeat', 'VB'), ('him', 'PRP'), ('and', 'CC'), ('that', 'DT'), (\"'s\", 'VBZ'), ('hard', 'JJ'), ('to', 'TO'), ('do', 'VB'), ('.', '.'), (\"''\", \"''\")], senses=('HARD1',)), SensevalInstance(word='hard-a', position=10, context=[('clever', 'NNP'), ('white', 'NNP'), ('house', 'NNP'), ('``', '``'), ('spin', 'VB'), ('doctors', 'NNS'), (\"''\", \"''\"), ('are', 'VBP'), ('having', 'VBG'), ('a', 'DT'), ('hard', 'JJ'), ('time', 'NN'), ('helping', 'VBG'), ('president', 'NNP'), ('bush', 'NNP'), ('explain', 'VB'), ('away', 'RB'), ('the', 'DT'), ('economic', 'JJ'), ('bashing', 'NN'), ('that', 'IN'), ('low-and', 'JJ'), ('middle-income', 'JJ'), ('workers', 'NNS'), ('are', 'VBP'), ('taking', 'VBG'), ('these', 'DT'), ('days', 'NNS'), ('.', '.')], senses=('HARD1',)), ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senseval.instances('hard.pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo, en la primera instancia (`SensevalInstance`) la palabra ambigua (`word`) es `‘hard-a’`, lo que indica que la palabra es `‘hard’` y en este caso la categoría gramatical es un adjetivo, identificado por el sufijo `‘-a’`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El campo `position` indica la posición en la oración en la que se encuentra la palabra ambigua, en este caso la palabra `‘hard’` se encuentra en la posición 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El campo `context` representa el contexto, es decir, la oración en la que se encuentra la palabra ambigua, en este ejemplo *«\"he may lose all popular support, but someone has to kill him to defeat him and that's hard to do.\"»*. El contexto viene representado por pares formados por una palabra y la correspondiente etiqueta gramatical. Por ejemplo, el par `(‘he’, ‘PRP’)` que aparece en el contexto indica que la categoría gramatical asociada a la palabra `‘he’` es un pronombre personal `‘PRP’`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, el campo `senses` contiene los posibles sentidos de la palabra ambigua, en el ejemplo `‘HARD1’`. Los sentidos del corpus hacen referencia a los sentidos de la palabra recogidos en la base de datos de relaciones léxicas WordNet<sup>1</sup>.\n",
    "\n",
    "\n",
    "<sup>1</sup> Puede que los sentidos que aparecen en Senseval 2 difieran de los que se encuentran actualmente en WordNet, debido a la constante actualización de este. En este laboratorio no será necesario trabajar con WordNet, se menciona como información adicional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso `‘HARD1’` hace referencia la primera definición de la palabra `‘hard’` que aparece en WordNet, a «difícil»,  *«difficult, hard (not easy; requiring great physical or mental effort to accomplish or comprehend or endure)»*. Esta información se puede obtener utilizando la interfaz de búsqueda web de WordNet cuyo resultado se muestra en la siguiente figura.\n",
    "\n",
    "***\n",
    "Accede al interfaz de búsqueda de WordNet desde la siguiente dirección web: http://wordnetweb.princeton.edu/perl/webwn\n",
    "\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** NLTK implementa también un lector para la información disponible en la base de datos de relaciones léxicas WordNet. Aunque no es necesario para realizar esta actividad de laboratorio, WordNet se puede importar utilizando el siguiente comando:\n",
    "\n",
    "> *from nltk.corpus import wordnet*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Giovanni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este laboratorio vas a trabajar con algoritmos basados en aprendizaje automático supervisado, por lo tanto, vas a tener que entrenar diferentes clasificadores que permitan desambiguar las palabras ambiguas en inglés «hard» y «serve», y vas a tener que evaluar el desempeño de los clasificadores creados.\n",
    "\n",
    "Las diferentes partes que forman este laboratorio se indican a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Parte 1: Análisis del corpus</span>\n",
    "\n",
    "Analiza el corpus Senseval 2 que vas a utilizar para entrenar los clasificadores. Para realizar el análisis utiliza las funcionalidades que aporta NLTK. Desarrolla el código necesario y responde a las siguientes preguntas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Cuántos posibles sentidos tienen las palabras ambiguas «hard» y «serve»? ¿Cuáles son esos sentidos? Para cada sentido indica la etiqueta que aparece en el corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Método que a partir de la palabra ambigua, o mejor dicho del nombre del archivo del corpus `word` para la palabra ambigua, obtiene cuáles son los posibles **sentidos de la palabra ambigua**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SensevalInstance(word='serve-v', position=42, context=[('some', 'DT'), ('tart', 'JJ'), ('fruits', 'NNS'), ('mixed', 'VBN'), ('with', 'IN'), ('greens', 'NNS'), ('make', 'VBP'), ('a', 'DT'), ('nice', 'JJ'), ('contrast', 'NN'), ('with', 'IN'), ('rich', 'JJ'), ('meat', 'NN'), ('dishes', 'NNS'), ('(', '('), ('see', 'VB'), ('orange', 'NNP'), ('and', 'CC'), ('onion', 'NNP'), ('salad', 'NNP'), (',', ','), ('page', 'NN'), ('111', 'CD'), (')', 'SYM'), (',', ','), ('but', 'CC'), ('if', 'IN'), ('you', 'PRP'), ('like', 'VB'), ('to', 'TO'), ('follow', 'VB'), ('the', 'DT'), ('meat', 'NN'), ('course', 'NN'), ('with', 'IN'), ('sweet', 'JJ'), ('fruit', 'NN'), (',', ','), ('it', 'PRP'), ('seems', 'VBZ'), ('wiser', 'JJR'), ('to', 'TO'), ('serve', 'VB'), ('it', 'PRP'), ('plain', 'JJ'), ('with', 'IN'), ('a', 'DT'), ('good', 'JJ'), ('sharp', 'JJ'), ('cheese', 'NN'), ('and', 'CC'), ('let', 'VB'), ('it', 'PRP'), ('take', 'VB'), ('the', 'DT'), ('place', 'NN'), ('of', 'IN'), ('a', 'DT'), ('sweet', 'JJ'), ('or', 'CC'), ('dessert', 'NN'), ('course', 'NN'), ('.', '.'), ('if', 'IN'), ('you', 'PRP'), ('insist', 'VBP'), ('on', 'IN'), ('serving', 'VBG'), ('fruit', 'NN'), ('as', 'IN'), ('a', 'DT'), ('salad', 'NN'), (',', ','), ('don', 'VB'), (\"'t\", 'NN'), ('cut', 'NN'), ('it', 'PRP'), ('into', 'IN'), ('cubes', 'NNS'), ('and', 'CC'), ('mix', 'NN'), ('it', 'PRP'), ('up', 'RB'), ('.', '.')], senses=('SERVE10',)), SensevalInstance(word='serve-v', position=25, context=[('to', 'TO'), ('increase', 'VB'), ('amount', 'NN'), ('of', 'IN'), ('stuffing', 'VBG'), (',', ','), ('preserve', 'VB'), ('ratio', 'NN'), ('of', 'IN'), ('half', 'NN'), ('as', 'IN'), ('much', 'JJ'), ('mushrooms', 'NNS'), ('as', 'IN'), ('bread', 'NN'), ('.', '.'), ('capon', 'NNP'), ('stuffed', 'VBD'), ('in', 'IN'), ('this', 'DT'), ('manner', 'NN'), ('would', 'MD'), ('most', 'RBS'), ('likely', 'JJ'), ('be', 'VB'), ('served', 'VBD'), ('with', 'IN'), ('pan-fried', 'JJ'), ('potatoes', 'NNS'), (',', ','), ('broccoli', 'NNS'), (',', ','), ('or', 'CC'), ('cauliflower', 'NN'), ('browned', 'VBN'), ('in', 'IN'), ('oil', 'NN'), ('.', '.')], senses=('SERVE10',)), ...]\n"
     ]
    }
   ],
   "source": [
    "def senses(word):\n",
    "    \"\"\"\n",
    "    This takes a target word from senseval-2 and it returns the list of possible senses for the word\n",
    "    \"\"\"\n",
    "    return list(set(\n",
    "        [instance.senses[0] for instance in senseval.instances(word)]\n",
    "    ))\n",
    "\n",
    "print(senseval.instances('serve.pos'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar los sentidos de las palabras ambiguas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HARD1', 'HARD2', 'HARD3']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senses('hard.pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SERVE2', 'SERVE6', 'SERVE10', 'SERVE12']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senses('serve.pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########## Aquí debes indicar tu respuesta ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Cuántas instancias hay en el corpus para cada uno de los sentidos de las palabras ambiguas «hard» y «serve»? Es decir, cuantas oraciones hay en el corpus etiquetadas con cada uno de los sentidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la palabra \"hard\", hay 3 posibilidades de sentidos.\n",
    "En el sentido que sea adjetivo, los significados pueden ser los siguientes\n",
    "\n",
    "    -HARD3:  (resisting weight or pressure)\n",
    "    -HARD1:  (not easy; requiring great physical or mental effort to accomplish or comprehend or endure) \"a difficult task\"; \"nesting places on the cliffs are difficult of access\"; \"difficult times\"; \"why is it so hard for you to keep a secret?\"\n",
    "    -HARD2: (dispassionate) \"took a hard look\"; \"a hard bargainer\"\n",
    "    \n",
    "En el sentido que sea un adverbio, los significados pueden ser los siguientes\n",
    "\n",
    "    -HARD3: (earnestly or intently) \"thought hard about it\"; \"stared hard at the accused\"\n",
    "    -HARD1: (with effort or force or vigor) \"the team played hard\"; \"worked hard all day\"; \"pressed hard on the lever\"; \"hit the ball hard\"; \"slammed the door hard\"\n",
    "    -HARD2: (with firmness) \"held hard to the railing\"\n",
    "   \n",
    "    \n",
    "Para la palabra \"serve\", hay 4 posibilidades de sentidos.\n",
    "En este caso solo hay posiblidades de que sea un verbo.\n",
    "\n",
    "    -SERVE10: (work for or be a servant to) \"May I serve you?\"; \"She attends the old lady in the wheelchair\"; \"Can you wait on our table, please?\"; \"Is a salesperson assisting you?\"; \"The minister served the King for many years\"\n",
    "    -SERVE6:  (provide (usually but not necessarily food)) \"We serve meals for the homeless\"; \"She dished out the soup at 8 P.M.\"; \"The entertainers served up a lively show\"\n",
    "    -SERVE2:  (do duty or hold offices; serve in a specific function) \"He served as head of the department for three years\"; \"She served in Congress for two terms\"\n",
    "    -SERVE12: (be sufficient; be adequate, either in quality or quantity) \"A few words would answer\"; \"This car suits my purpose  well\"; \"Will 100 do?\"; \"A `B' grade doesn't suffice to get me into medical school\"; \"Nothing else will serve\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Método que obtiene todas las **instancias de un posible sentido de la palabra ambigua** a partir de la lista de instancias de una palabra `instances` y el nombre del sentido palabra ambigua `sense`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sense_instances(instances, sense):\n",
    "    \"\"\"\n",
    "    This returns the list of instances in instances that have the sense sense\n",
    "    \"\"\"\n",
    "    return [\n",
    "        instance for instance in instances if instance.sense[0] == sense\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'HARD1': 3455, 'HARD2': 502, 'HARD3': 376})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist([i.senses[0] for i in senseval.instances('hard.pos')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'SERVE10': 1814, 'SERVE12': 1272, 'SERVE2': 853, 'SERVE6': 439})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist([i.senses[0] for i in senseval.instances('serve.pos')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########## Aquí debes indicar tu respuesta ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En el contexto, las palabras ambiguas pueden aparecer en diferentes formas gramaticales. Por ejemplo, en el caso de la palabra ambigua *«hard»*, esta aparece tanto la forma base, el adjetivo *«hard»* como en comparativo *«harder»* y como en superlativo *«hardest»*. ¿Qué formas gramaticales aparecen en el contexto para cada una de las palabas ambiguas *«hard»* y *«serve»*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Método que muestra las diferentes **versiones de la palabra ambigua** a partir del nombre del archivo del corpus `word` para la palabra ambiguala palabra ambigua:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens(word):\n",
    "    \"\"\"\n",
    "    This takes a target word from senseval-2 and it returns the list of possible tokens for the word\n",
    "    \"\"\"\n",
    "    token = set()\n",
    "\n",
    "    for instance in senseval.instances(word):\n",
    "        for element in instance.context:\n",
    "            if element[0] == word.split('.')[0]:\n",
    "                token.add(element[1])\n",
    "        \n",
    "    return list(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar las diferentes versiones de la palabra ambigua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JJ']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens('hard.pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VBP', 'VB']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens('serve.pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########## Aquí debes indicar tu respuesta ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Tienen todas las instancias que forman el corpus el formato que se ha descrito anteriormente? Si hay alguna instancia que no cumpla con ese formato, indica cuales serían las incongruencias que presenta y muestra algunos ejemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errores en palabra hard:  []\n",
      "Errores en palabra serve:  []\n"
     ]
    }
   ],
   "source": [
    "def falla(word):\n",
    "    fallas = []\n",
    "    \n",
    "    for instancia in senseval.instances(word):\n",
    "        for atributo in ['word', 'position', 'context', 'senses']:\n",
    "            if len(instancia.__dict__.keys()) > 4:\n",
    "                fallas.append(instancia)\n",
    "                \n",
    "    return fallas\n",
    "\n",
    "print('Errores en palabra hard: ', falla('hard.pos'))\n",
    "print('Errores en palabra serve: ', falla('serve.pos'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########## Aquí debes indicar tu respuesta ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Parte 2: Extracción de características</span>\n",
    "\n",
    "Para poder entrenar un clasificador es necesario extraer un conjunto de características lingüísticas a partir del corpus etiquetado. Por lo tanto, debes crear el código en Python que te permita extraer diferentes conjuntos de características a partir de Senseval 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción de características basada en las palabras vecinas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debes extraer un **conjunto de características basado en las palabras vecinas**. Para una instancia del corpus, debes desarrollar el código que sea capaz de extraer el vector de características que indican si las palabras de un vocabulario, que se debe construir previamente, aparecen o no en el contexto (la oración completa en que aparece la palabra ambigua).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para una instancia de la palaba ambigua «hard» su contexto se muestra a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_hard = senseval.instances('hard.pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_hard_1 = instances_hard[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('clever', 'NNP'),\n",
       " ('white', 'NNP'),\n",
       " ('house', 'NNP'),\n",
       " ('``', '``'),\n",
       " ('spin', 'VB'),\n",
       " ('doctors', 'NNS'),\n",
       " (\"''\", \"''\"),\n",
       " ('are', 'VBP'),\n",
       " ('having', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('hard', 'JJ'),\n",
       " ('time', 'NN'),\n",
       " ('helping', 'VBG'),\n",
       " ('president', 'NNP'),\n",
       " ('bush', 'NNP'),\n",
       " ('explain', 'VB'),\n",
       " ('away', 'RB'),\n",
       " ('the', 'DT'),\n",
       " ('economic', 'JJ'),\n",
       " ('bashing', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('low-and', 'JJ'),\n",
       " ('middle-income', 'JJ'),\n",
       " ('workers', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('taking', 'VBG'),\n",
       " ('these', 'DT'),\n",
       " ('days', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst_hard_1.context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suponiendo que el vocabulario usado para crear extraer las características es el siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`['time', 'would', 'get', 'work', 'find', 'make']`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces el vector de características extraídas para esa instancia sería:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`{'contains(time)': True, \n",
    "'contains(would)': False, \n",
    "'contains(get)': False, \n",
    "'contains(work)': False, \n",
    "'contains(find)': False, \n",
    "'contains(make)': False}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este vector de características indica que en el contexto de la palabra ambigua aparece la palabra *«time»* y no aparecen las palabras *«would»*, *«get»*, *«work»*, *«find»* y *«make»*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para extraer el vector de características basado en las palabras vecinas debes seguir los siguientes pasos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Construcción del vocabulario o bags of words. \n",
    "\n",
    "Como ya se ha indicado, para poder obtener el vector de características, se debe construir previamente un vocabulario. Para cada una de las palabras del vocabulario, se debe consultar si la palabra aparece en el contexto de la palabra ambigua. Si la palabra del vocabulario aparece en el contexto entonces en el vector de características aparecerá True para esa palabra y si no, False. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomemos como ejemplo un vocabulario creado sobre el que se ha construido el vector de características. Este vocabulario es `['time', 'would', 'get', 'work', 'find', 'make']`. Este vocabulario se usará posteriormente para construir el vector de características del ejemplo que usamos para darte una orientación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **¿Cómo construyo mi vocabulario o bags of words?** Lo que debes hacer para tu entrega de este laboratorio es utilizar como vocabulario las m palabras más frecuentes que aparecen en las instancias que conforman el conjunto de datos, es decir en las oraciones que contienen las palabras ambiguas y que forman parte del corpus. Entonces, para crear la **bag of words** (bolsa de palabras) debes extraer el conjunto de las n palabras más frecuentes. Para ello te puedes ayudar de la función `nltk.FreqDist()` que proporciona información sobre la distribución de frecuencias de las palabras que aparecen en un texto. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cuando obtengas las palabras más frecuentes, debes eliminar los signos que puntuación y las palabras vacías (aquellas sin significado como artículos, pronombres o preposiciones, las llamadas stop words en inglés). También debes eliminar las diferentes formas gramaticales de la palabra ambigua, por ejemplo, para desambiguar la palabra *«hard»* no tendría sentido utilizar la palabra *«harder»* ni la palabra *«hardest»*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Para la eliminación del conjunto de palabras no útiles del vocabulario se puede usar un código parecido al que se indica a continuación. Debes tener en cuenta que **en el código faltaría añadir las palabras que has identificado en la Parte 1** de este laboratorio como las diferentes formas gramaticales de las palabras ambiguas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Giovanni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "OTHER_WORDS = [\"''\", \"'d\", \"'ll\", \"'m\", \"'re\", \"'s\", \"'t\", \"'ve\", '--', '000', '1', '2', '3', '4', '5',\n",
    "               '6', '8', '10', '15', '30', 'I', 'F', '``', 'also', \"don'\", 'n', 'one', 'said', 'say',\n",
    "               'says', 'u', 'us', 'hard', 'harder', 'hardest']\n",
    "STOPWORDS_SET = set(stopwords.words('english')).union(set(string.punctuation), set(OTHER_WORDS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ejemplo de vocabulario para un tamaño de 6. Por ejemplo, si se quiere entrenar un clasificador que permita identificar los diferentes sentidos de la palabra «hard» y se utilizan para entrenar y validar el modelo las instancias etiquetadas para esta palabra, la bolsa de palabras en el caso de considerar las seis palabras más frecuentes (m=6) sería la presentada anteriormente `['time', 'would', 'get', 'work', 'find', 'make']`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Método que devuelve el **vocabulario** formado por las `m` palabras más frecuentes en el contexto de una palabra ambigua a partir de un conjunto de instancias `instances` y el conjunto de palabras no útiles `stopwords` (Nota: Recuerda que se deben eliminar las diferentes formas gramaticales de la palabra ambigua):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vocab(instances, stopwords=STOPWORDS_SET, m=250):\n",
    "    \"\"\"\n",
    "    Given a list of senseval instances, return a list of the m most frequent words that\n",
    "    appears in its context (i.e., the sentence with the target word in), output is in order\n",
    "    of frequency.\n",
    "    \"\"\"\n",
    "    return [w for w,f in extract_vocab_frequency(instances,stopwords,m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vocab_frequency(instances, stopwords=STOPWORDS_SET, m=250):\n",
    "    \"\"\"\n",
    "    Given a list of senseval instances, return a list of the m most frequent words that\n",
    "    appears in its context (i.e., the sentence with the target word in), output is in order\n",
    "    of frequency and includes also the number of instances in which that key appears in the\n",
    "    context of instances.\n",
    "    \"\"\"\n",
    "    contador_instancias = {}\n",
    "    for instance in instances:\n",
    "        for word in instance.context:\n",
    "            if word[0] not in contador_instancias:\n",
    "                contador_instancias[word[0]] = 1\n",
    "            else:\n",
    "                contador_instancias[word[0]] += 1\n",
    "    return [(k, v) for k, v in sorted(contador_instancias.items(), key = lambda item : item[1], reverse = True)\n",
    "           if k not in stopwords][:m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar el vocabulario de tamaño de 6 para la palabra «hard», es decir el vocabulario creado usando las instancias de la a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_6 = extract_vocab(instances_hard, STOPWORDS_SET, m=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time', 'would', 'get', 'work', 'make', 'find']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Construcción del conjunto de características basado en palabras vecinas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliza un diccionario en Python para guardar el conjunto de características. La clave del diccionario serán las palabras del vocabulario y el valor debe ser un booleano para indicar la aparición o no de las palabras en el contexto. Por ejemplo, en el vector de características `{'contains(time)': True, 'contains(would)': False, 'contains(get)': False, 'contains(work)': False, 'contains(find)': False, 'contains(make)': False}` una de las claves del diccionario es `'contains(time)'` y su valor es `True`  lo que indica que en el contexto de la palabra ambigua aparece la palabra *«time»*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Debes mostrar el vector de características resultante para una de las instancias del corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Importante:** En el cómputo del vector de características basado en las palabras vecinas debes utilizar como contexto la oración completa donde aparece la palabra ambigua. Es decir, todas las palabras que forman la oración guardada en el campo  `context` de la instancia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Método que devuelve el conjunto de características basado en palabras vecinas para una instancia `instance` a partir de un vocabulario `vocab` (Nota: el parámetro `dist` no debes usarlo):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wsd_caracteristicas_palabras_vecinas(instance, vocab, dist=2):\n",
    "    \"\"\"\n",
    "    Create a featureset where every key returns False unless it occurs in the\n",
    "    instance's context\n",
    "    \"\"\"\n",
    "    atributos = {}\n",
    "    \n",
    "    for palabra in vocab:\n",
    "        atributos[f\"palabra('{palabra}')\"] = True if palabra in [palabras[0] for palabras in instance.context] else False\n",
    "                \n",
    "    return atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar el vector de características basado en palabras vecinas para una de las instancias del corpus usando el vocabulario de seis palabras calculado previamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"palabra('time')\": True,\n",
       " \"palabra('would')\": False,\n",
       " \"palabra('get')\": False,\n",
       " \"palabra('work')\": False,\n",
       " \"palabra('make')\": False,\n",
       " \"palabra('find')\": False}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsd_caracteristicas_palabras_vecinas(inst_hard_1, vocab_6, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción de características basada en características de colocación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debes extraer también un **conjunto de características de colocación**. Para una instancia del corpus, debes desarrollar el código que sea capaz de extraer el vector de características formado por la secuencia de n palabras que ocurren antes de la palabra ambigua y la secuencia de n palabras que ocurren después de la palabra ambigua, los llamados n-gramas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para una instancia de la palaba ambigua «hard» su contexto se muestra a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_hard_2737 = instances_hard[2737]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('``', '``'),\n",
       " ('it', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('very', 'RB'),\n",
       " ('interesting', 'JJ'),\n",
       " ('place', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('work', 'VB'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('i', 'PRP'),\n",
       " ('can', 'MD'),\n",
       " ('see', 'VB'),\n",
       " ('why', 'WRB'),\n",
       " ('some', 'DT'),\n",
       " ('people', 'NNS'),\n",
       " ('have', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " ('hard', 'JJ'),\n",
       " ('time', 'NN'),\n",
       " ('imagining', 'VBG'),\n",
       " ('what', 'WP'),\n",
       " ('it', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('like', 'IN'),\n",
       " (',', ','),\n",
       " ('\"', '\"'),\n",
       " ('says', 'VBZ'),\n",
       " ('nate', 'NNP'),\n",
       " ('gossett', 'NNP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst_hard_2737.context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces el vector de características de colocación para el bigrama anterior y posterior sería:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`{'previous(have a)': True, 'next(time imagining)': True}` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este vector de características indica que antes de la palabra ambigua se encuentran las palabras *«have a»* y después de la palabra ambigua las palabras *«time imagining»*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **¿Cómo construyo mi conjunto y que n utilizo?** Utiliza un diccionario en Python para guardar el conjunto de características, la clave del diccionario debe indicar la secuencia de palabras de contexto y si aparecen antes o después de la palabra ambigua y el valor asociado a la clave debe ser un booleano verdadero. Usaremos **n=2**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Por ejemplo, en el vector de características `{'previous(have a)': True, 'next(time imagining)': True}` una de las claves del diccionario es `'previous(have a)'` y su valor es `True` lo que indica que antes de la palabra ambigua se encuentran las palabras *«have a»*. En este caso, al tener secuencias de dos palabras (*n=2*), se están considerando bigramas y la ventana tendría tamaño cinco (*2n+1*). Por lo tanto, si la palabra ambigua es *«hard» en el contexto guardado en el campo context de la instancia, aparece la siguiente parte de la frase «have a hard time imagining»."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Debes mostrar el vector de características resultante para una de las instancias del corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Importante:** Debes tener en cuenta los posibles casos en los que la palabra ambigua aparezca al principio o final de la frase, ya que en esas instancias no vas a poder obtener una secuencia de palabras de longitud n. Por ejemplo, para la instancia cuyo contexto es: `[('some', 'DT'), ('hard', 'JJ'), ('choices', 'NNS'), ('had', 'VBD'), ('to', 'TO'), ('be', 'VB'), ('made', 'VBN'), …]` si n=2 deberías obtener el siguiente vector de características: `{'previous(some)': True, 'next(choices had)': True}`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Nota:** aunque no es imprescindible para realizar esta actividad de laboratorio, puedes utilizar las funcionalidades para trabajar con n-gramas que ofrece NLTK. Estas se pueden importar utilizando el siguiente comando:\n",
    "\n",
    "> *from nltk import ngrams*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Método que devuelve el conjunto de características de colocación para una instancia `instance` usando los n-gramas anterior y posterior donde la longitud de secuencia es de `dist` palabras (Nota: el parámetro `vocab` no debes usarlo):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wsd_caracteristicas_colocacion(instance, vocab, dist = 2):\n",
    "    features = {}\n",
    "    \n",
    "    pos = [word_context[0] for word_context in instance.context].index(instance.context[instance.position][0])\n",
    "    start = 0 if pos - dist < 0 else pos - dist\n",
    "    end = len(instance.context) if dist + pos > len(instance.context) else dist + pos + 1\n",
    "    for word in vocab:\n",
    "        features[f\"contains('{word}')\"] = True if word in [word_context[0] for word_context in instance.context[start:end]] else False\n",
    "          \n",
    "      \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar el vector de características de colocación para una de las instancias del corpus usando n=2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"contains('time')\": True,\n",
       " \"contains('would')\": False,\n",
       " \"contains('get')\": False,\n",
       " \"contains('work')\": False,\n",
       " \"contains('make')\": False,\n",
       " \"contains('find')\": False}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsd_caracteristicas_colocacion(inst_hard_2737, vocab_6, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Parte 3: Entrenamiento de clasificadores</span>\n",
    "\n",
    "Debes entrenar diferentes clasificadores que permitan desambiguar las palabras ambiguas en inglés «hard» y «serve». Además, vas a tener que evaluar el desempeño de los clasificadores creados. Por lo tanto, debes crear el código en Python que te permita entrenar estos clasificadores y evaluarlos. \n",
    "\n",
    "El tipo de clasificador que vas a utilizar en este laboratorio es el Naive Bayes. Para importar el clasificador y el paquete que te permita evaluar su rendimiento debes utilizar el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import accuracy, NaiveBayesClassifier\n",
    "from nltk import ConfusionMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hayas importado los paquetes anteriores, para entrenar un clasificador Naïve Bayes puedes usar el comando `NaiveBayesClassifier.train()` y para evaluarlo `accuracy()`. Además, puedes utilizar el clasificador entrenado para clasificar una instancia utilizando su método `classify()`. Por último, puedes obtener la matriz de confusión utilizando el comando `nltk.ConfusionMatrix()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar esta parte del laboratorio debes seguir los siguientes pasos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.\tEntrenamiento de dos clasificadores para la palabra «hard». "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debes entrenar dos clasificadores que permitan desambiguar la palabra «hard», es decir, que debes entrenar los clasificadores utilizando las instancias disponibles en el corpus Senseval 2 para esta palabra ambigua."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Conjuntos de entrenamiento y test.** Para entrenar y validar divide las instancias disponibles en una proporción del 80-20 % y recuerda que en el conjunto de datos de entrenamiento deben aparecer instancias de todas las clases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Clasificador basado en las palabras vecinas.** Con el conjunto de datos de entrenamiento, entrena un clasificador para «hard» que use como características el conjunto basado en las **palabras vecinas** cuyo código has implementado en la parte 2 de este laboratorio. Para definir el vocabulario utiliza las **250** palabras más frecuentes (**m=250**). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Clasificador basado en características de colocación.** Con el conjunto de datos de entrenamiento, entrena un clasificador para «hard» que use como conjunto de características las de colocación cuyo código has implementado en la parte 2 de este laboratorio. Para definir la **ventana de contexto** utiliza la secuencia de dos palabras que ocurren antes de la palabra ambigua y la secuencia de dos palabras que ocurren después de esta **(n=2)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wsd_clasificador(word, features, stopwords_list = STOPWORDS_SET, number=250, \n",
    "                     distance=2, errors=False, confusion_matrix=False):\n",
    "    \"\"\"\n",
    "    This function takes as arguments:\n",
    "        a target word from senseval2;\n",
    "        a feature set (this can be wsd_caracteristicas_palabras_vecinas or wsd_caracteristicas_colocacion);\n",
    "        a list of stopwords \n",
    "        a number (defaults to 250), which determines for wsd_caracteristicas_palabras_vecinas the number of\n",
    "            most frequent words within the context of a given sense that you use to classify examples;\n",
    "        a distance (defaults to 2) which determines the size of the window for wsd_caracteristicas_colocacion;\n",
    "        errors (defaults to false), which if set to True prints the errors;\n",
    "        confusion_matrix (defaults to False), which if set to True prints a confusion matrix.\n",
    "\n",
    "    Calling this function splits the senseval data for the word into a training set and a test set (the way it does\n",
    "    this is the same for each call of this function, because the argument to random.seed is specified,\n",
    "    but removing this argument would make the training and testing sets different each time you build a classifier).\n",
    "\n",
    "    It then trains the trainer on the training set to create a classifier that performs WSD on the word,\n",
    "    using features (with number or distance where relevant).\n",
    "\n",
    "    It then tests the classifier on the test set, and prints its accuracy on that set.\n",
    "\n",
    "    If error==True, then the errors of the classifier over the test set are printed out.\n",
    "    For each error four things are recorded: (i) the example number within the test data (this is simply the index of the\n",
    "    example within the list test_data); (ii) the sentence that the target word appeared in, (iii) the\n",
    "    (incorrect) derived label, and (iv) the good label.\n",
    "\n",
    "    If confusion_matrix==True, then calling this function prints out a confusion matrix, where each cell [i,j]\n",
    "    indicates how often label j was predicted when the correct label was i (so the diagonal entries indicate labels\n",
    "    that were correctly predicted).\n",
    "    \"\"\"\n",
    "\n",
    "    parametro = [(instancia, instancia.senses[0]) for instancia in senseval.instances(word)]\n",
    "    estados = (estado for (i, estado) in parametro)\n",
    "    instancias = senseval.instances(word)\n",
    "    palabras = extract_vocab(instancias, stopwords = STOPWORDS_SET, m = number)\n",
    "    feature_set = [features(i, palabras, distance) for (i, _) in parametro]\n",
    "    data = list(zip(feature_set, estados))\n",
    "    \n",
    "    # Split the instances into a training and test set\n",
    "\n",
    "    np.random.seed(3000)\n",
    "    np.random.shuffle(data)\n",
    "    train = data[:int(0.8 * len(data))]\n",
    "    test = data[int(.8 * len(data)):]\n",
    "\n",
    "    \n",
    "    # Train classifier\n",
    "    \n",
    "    classifier = NaiveBayesClassifier.train(train)\n",
    "\n",
    "    \n",
    "    # Test classifier\n",
    "    \n",
    "    acc = nltk.classify.accuracy(classifier, test)\n",
    "        \n",
    "    print('Accuracy: %6.4f' % acc)\n",
    "    \n",
    "    if errors==True:\n",
    "        errors = []\n",
    "        for (instancia, label) in test:\n",
    "            i = classifier.classify(instancia)\n",
    "\n",
    "            if i != label:\n",
    "                con = instancia[instancia.context]\n",
    "                posicion = instancia.position\n",
    "                i_numero = str(test.index((instancia, label)))\n",
    "                lista = []\n",
    "                for (word, tag) in con:\n",
    "                    lista.append(word)\n",
    "                \n",
    "                err_visual = lista[posicion].upper()\n",
    "                lista_errores = lista[0:posicion] + [err_visual] + lista[posicion + 1:]\n",
    "                oracion = ' '.join(lista_errores)\n",
    "                errors.append([i_numero, oracion, i, label])\n",
    "        error_numero = len(errors)\n",
    "        print('Errores: ')\n",
    "\n",
    "        for error in errors:\n",
    "            print(str(errors.index(error)+1) + error)\n",
    "    palabras_ = extract_vocab(senseval.instances(word), STOPWORDS_SET, m=6)\n",
    "\n",
    "    if confusion_matrix==True:\n",
    "        good = [label for (i, label) in test]\n",
    "        derived = [classifier.classify(i) for (i, label) in test]\n",
    "\n",
    "        print('Matriz de confusión: ')\n",
    "        mc = nltk.ConfusionMatrix(good, derived)\n",
    "        print(mc)\n",
    "        \n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\tValidación de los clasificadores para la palabra «hard».  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando el conjunto de datos de test que has generado previamente, obtén la exactitud (accuracy) y la matriz de confusión para cada uno de los dos clasificadores que permiten desambiguar el sentido de la palabra «hard». "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Debes mostrar la exactitud (accuracy) y la matriz de confusión resultantes de la validación de cada uno de los dos clasificadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8662\n",
      "Matriz de confusión: \n",
      "      |   H   H   H |\n",
      "      |   A   A   A |\n",
      "      |   R   R   R |\n",
      "      |   D   D   D |\n",
      "      |   1   2   3 |\n",
      "------+-------------+\n",
      "HARD1 |<679> 14   8 |\n",
      "HARD2 |  41 <51>  1 |\n",
      "HARD3 |  50   2 <21>|\n",
      "------+-------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clasificador_hard_vecinas = wsd_clasificador('hard.pos', wsd_caracteristicas_palabras_vecinas, \n",
    "                                             number=250, errors=False, confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8754\n",
      "Matriz de confusión: \n",
      "      |   H   H   H |\n",
      "      |   A   A   A |\n",
      "      |   R   R   R |\n",
      "      |   D   D   D |\n",
      "      |   1   2   3 |\n",
      "------+-------------+\n",
      "HARD1 |<681> 10  10 |\n",
      "HARD2 |  33 <58>  2 |\n",
      "HARD3 |  52   1 <20>|\n",
      "------+-------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clasificador_hard_colocacion = wsd_clasificador('hard.pos', wsd_caracteristicas_colocacion, distance=2, \n",
    "                                                errors=False, confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debes comparar y analizar los resultados de rendimiento de los clasificadores. Para ello responde a las siguientes preguntas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ¿Cuál es el conjunto de características que aporta mejores resultados? ¿Por qué? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto que toma los valores de la cercania de cada palabra con respecto a la que es el objetivo, ya que esta cercania o \"distancia\" hace que las plaabras puedan tener diferentes significados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ¿Cuál es el sentido más difícil de identificar? ¿Por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HARD3 ya que no se tienen tantos valores para analizar, como con respecto en las otras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ¿Qué posibles mejoras se podrían aplicar para mejorar el rendimiento de los clasificadores creados? No es necesario que las implementes, solo que las comentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mi parecer se podrian dar mas muestras para que se tengan mas valores para analizar y asi poder hacer que las palabras no tengan un significado diferente del cual se están usando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.\tInstancias clasificadas incorrectamente para «hard».   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el clasificador que permite desambiguar la palabra «hard» y que utiliza las características de colocación, obtén las instancias que pertenecen al sentido ‘HARD1’ y que se han clasificado incorrectamente. Presenta en el informe la oración en la que aparece la palabra ambigua (el contexto) para cada una de esas instancias y la etiqueta en la que han sido erróneamente clasificadas.\n",
    "\n",
    "Para el clasificador que permite desambiguar la palabra «hard» y que utiliza las características de colocación, obtén las instancias que pertenecen al sentido ‘HARD1’ y que se han clasificado incorrectamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Presenta la oración en la que aparece la palabra ambigua (el contexto) para cada una de esas instancias y la etiqueta en la que han sido erróneamente clasificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8754\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'context'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Giovanni\\Documents\\Maestría\\Asignaturas\\6. Procesamiento del Lenguaje Natural\\Actividades\\Act 3. Desambiguación del sentido de las palabras\\Actividad3.ipynb Celda 124\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Giovanni/Documents/Maestr%C3%ADa/Asignaturas/6.%20Procesamiento%20del%20Lenguaje%20Natural/Actividades/Act%203.%20Desambiguaci%C3%B3n%20del%20sentido%20de%20las%20palabras/Actividad3.ipynb#Y233sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m clasificador_hard_colocacion \u001b[39m=\u001b[39m wsd_clasificador(\u001b[39m'\u001b[39;49m\u001b[39mhard.pos\u001b[39;49m\u001b[39m'\u001b[39;49m, wsd_caracteristicas_colocacion, distance \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Giovanni/Documents/Maestr%C3%ADa/Asignaturas/6.%20Procesamiento%20del%20Lenguaje%20Natural/Actividades/Act%203.%20Desambiguaci%C3%B3n%20del%20sentido%20de%20las%20palabras/Actividad3.ipynb#Y233sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                                                 errors \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m, confusion_matrix \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;32mc:\\Users\\Giovanni\\Documents\\Maestría\\Asignaturas\\6. Procesamiento del Lenguaje Natural\\Actividades\\Act 3. Desambiguación del sentido de las palabras\\Actividad3.ipynb Celda 124\u001b[0m in \u001b[0;36mwsd_clasificador\u001b[1;34m(word, features, stopwords_list, number, distance, errors, confusion_matrix)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Giovanni/Documents/Maestr%C3%ADa/Asignaturas/6.%20Procesamiento%20del%20Lenguaje%20Natural/Actividades/Act%203.%20Desambiguaci%C3%B3n%20del%20sentido%20de%20las%20palabras/Actividad3.ipynb#Y233sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m i \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39mclassify(instancia)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Giovanni/Documents/Maestr%C3%ADa/Asignaturas/6.%20Procesamiento%20del%20Lenguaje%20Natural/Actividades/Act%203.%20Desambiguaci%C3%B3n%20del%20sentido%20de%20las%20palabras/Actividad3.ipynb#Y233sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m label:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Giovanni/Documents/Maestr%C3%ADa/Asignaturas/6.%20Procesamiento%20del%20Lenguaje%20Natural/Actividades/Act%203.%20Desambiguaci%C3%B3n%20del%20sentido%20de%20las%20palabras/Actividad3.ipynb#Y233sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     con \u001b[39m=\u001b[39m instancia[instancia\u001b[39m.\u001b[39;49mcontext]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Giovanni/Documents/Maestr%C3%ADa/Asignaturas/6.%20Procesamiento%20del%20Lenguaje%20Natural/Actividades/Act%203.%20Desambiguaci%C3%B3n%20del%20sentido%20de%20las%20palabras/Actividad3.ipynb#Y233sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     posicion \u001b[39m=\u001b[39m instancia\u001b[39m.\u001b[39mposition\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Giovanni/Documents/Maestr%C3%ADa/Asignaturas/6.%20Procesamiento%20del%20Lenguaje%20Natural/Actividades/Act%203.%20Desambiguaci%C3%B3n%20del%20sentido%20de%20las%20palabras/Actividad3.ipynb#Y233sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     i_numero \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(test\u001b[39m.\u001b[39mindex((instancia, label)))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'context'"
     ]
    }
   ],
   "source": [
    "clasificador_hard_colocacion = wsd_clasificador('hard.pos', wsd_caracteristicas_colocacion, distance = 2, \n",
    "                                                errors = True, confusion_matrix = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########## Aquí debes indicar tu respuesta ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.\tEntrenamiento y validación de dos clasificadores para la palabra «serve».   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repite el proceso anterior para entrenar y validar dos clasificadores que permitan desambiguar la palabra «serve». Puedes aprovechar el código que has generado anteriormente.\n",
    "\n",
    "-\tCrea los conjuntos de entrenamiento y test para las instancias donde la palabra ambigua es «serve». Mantén la proporción del 80-20 % para la creación de los conjuntos de entrenamiento y de test. \n",
    "\n",
    "-\tEntrena un clasificador para «serve» que use como características el conjunto basado en las **palabras vecinas**. Para definir el vocabulario utiliza las **250** palabras más frecuentes (**m=250**).\n",
    "\n",
    "-\tEntrena un clasificador para «serve» que use como conjunto **de características las de colocación**. Para definir la **ventana de contexto** utiliza la secuencia de dos palabras que ocurren antes de la palabra ambigua y la secuencia de dos palabras que ocurren después de esta **(n=2)**. \n",
    "\n",
    "-\tObtén el valor la exactitud (accuracy) para cada uno de los dos clasificadores que permiten desambiguar el sentido de la palabra «sense». "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7454\n",
      "Matriz de confusión: \n",
      "        |   S   S         |\n",
      "        |   E   E   S   S |\n",
      "        |   R   R   E   E |\n",
      "        |   V   V   R   R |\n",
      "        |   E   E   V   V |\n",
      "        |   1   1   E   E |\n",
      "        |   0   2   2   6 |\n",
      "--------+-----------------+\n",
      "SERVE10 |<300>  7  48   3 |\n",
      "SERVE12 |  10<192> 51  10 |\n",
      " SERVE2 |  28  15<113> 14 |\n",
      " SERVE6 |   5  14  18 <48>|\n",
      "--------+-----------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clasificador_serve_vecinas = wsd_clasificador('serve.pos', wsd_caracteristicas_palabras_vecinas, number=250, \n",
    "                                              confusion_matrix = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5719\n",
      "Matriz de confusión: \n",
      "        |   S   S         |\n",
      "        |   E   E   S   S |\n",
      "        |   R   R   E   E |\n",
      "        |   V   V   R   R |\n",
      "        |   E   E   V   V |\n",
      "        |   1   1   E   E |\n",
      "        |   0   2   2   6 |\n",
      "--------+-----------------+\n",
      "SERVE10 |<273> 70   9   6 |\n",
      "SERVE12 |  92<162>  6   3 |\n",
      " SERVE2 |  88  37 <40>  5 |\n",
      " SERVE6 |  35  21   3 <26>|\n",
      "--------+-----------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clasificador_serve_colocacion = wsd_clasificador('serve.pos', wsd_caracteristicas_colocacion, distance=2, errors=False, \n",
    "                                                confusion_matrix = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.\tAnálisis de resultados del rendimiento de los clasificadores y conclusiones sobre el uso de aprendizaje automático supervisado para desambiguar el sentido de las palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presenta una tabla resumen con los valores de exactitud para cada uno de los 4 clasificadores (dos para cada palabra ambigua) que has entrenado previamente y responde a las siguientes preguntas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########## Aquí debes indicar tu respuesta ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Por qué no es justo comparar directamente la exactitud aportada por los clasificadores que han aprendido diferentes palabras ambiguas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porque cada palabra puede variar dependiendo del numero de muestras y de la proximidad con las demas palabras, las cuales le pueden dar un sentido diferente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Cómo podrías hacerlo para que la comparación entre clasificadores que desambiguan palabras diferentes tenga sentido?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Darle mas valores a analizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compara la exactitud de los clasificadores con la que proporcionaría un clasificador que asignara el sentido de forma aleatoria. ¿Cuál sería el mejor clasificador tomando como referencia (baseline), el clasificador aleatorio?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El clasificador aplicado en la palabra HARD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hayas implementado diferentes clasificadores para desambiguar el sentido de diferentes palabras y analizado su desempeño, reflexiona sobre el uso de algoritmos basados en aprendizaje automático supervisado para resolver la tarea de desambiguación del sentido de las palabras. Para ello responde de forma razonada a las siguientes preguntas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Cuáles son las limitaciones de los clasificadores que has creado para la desambiguación del sentido de las palabras?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los numeros de datos que requieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Qué alternativas propondrías para superar esas limitaciones y obtener algoritmo que resuelva mejor el problema de la desambiguación del sentido de las palabras?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un algoritmo que clasifique mejor el sentido de las palabras, recurriria a arboles de desición para encontrar un resultado más óptimo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "650612b72461e7c5146c3d42cdb3c38eddfaae87360e368e7b4bd3d042dfdcd3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
